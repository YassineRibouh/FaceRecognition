{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train MultiTask Models",
   "id": "cbf596536aac9e85"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-19T00:23:15.167734Z",
     "start_time": "2024-11-19T00:23:09.973341Z"
    }
   },
   "source": [
    "import os, sys\n",
    "import json\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T00:23:15.199756Z",
     "start_time": "2024-11-19T00:23:15.184703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..','data_processing')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..','models')))"
   ],
   "id": "854b691a50e43f21",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from multitask_preprocessing import train_dataset, val_dataset, test_dataset",
   "id": "446668ea6f4c3f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T22:03:20.969358Z",
     "start_time": "2024-11-18T22:03:20.910762Z"
    }
   },
   "cell_type": "code",
   "source": "from efficientnetb0 import create_efficientnetb0_multi_task, create_efficientnetb0_multi_task_v2, create_efficientnetb3_multi_task, create_efficientnetb3_multi_task_v2, create_efficientnetb3_multi_task_v3",
   "id": "2534077d7721e382",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:20:49.223462Z",
     "start_time": "2024-11-16T13:20:49.180164Z"
    }
   },
   "cell_type": "code",
   "source": "from resnet50 import create_resnet50_multi_task, create_resnet50_multi_task_v2",
   "id": "623aa196ac0c27a1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:20:49.269304Z",
     "start_time": "2024-11-16T13:20:49.230838Z"
    }
   },
   "cell_type": "code",
   "source": "from mobileNet import create_mobileNet_multi_task, create_mobileNet_multi_task_v2",
   "id": "eba63b38aaaebe23",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T00:23:20.201060Z",
     "start_time": "2024-11-19T00:23:20.172476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_save_multi_task_model(model_name,\n",
    "                                    model_function,\n",
    "                                    dropout_rate,\n",
    "                                    results_dir='../results/Multi_Task',\n",
    "                                    epochs=10,\n",
    "                                    learning_rate=1e-4,\n",
    "                                    patience=5):\n",
    "\n",
    "\n",
    "    # Setup Directories\n",
    "\n",
    "\n",
    "    model_dir = os.path.join(results_dir, model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Initialize the Multi-Task Model\n",
    "\n",
    "\n",
    "    model = model_function(dropout_rate)\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    # Compile the Model\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss={\n",
    "            'face_output': 'binary_crossentropy',\n",
    "            'age_output': 'categorical_crossentropy',\n",
    "            'gender_output': 'binary_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'face_output': 'binary_accuracy',\n",
    "            'age_output': 'categorical_accuracy',\n",
    "            'gender_output': 'binary_accuracy'\n",
    "        },\n",
    "        weighted_metrics={\n",
    "            'age_output': 'categorical_accuracy',\n",
    "            'gender_output': 'binary_accuracy'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_age_output_categorical_accuracy',\n",
    "            factor=0.5,\n",
    "            patience=patience,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Train the Model\n",
    "\n",
    "    print(f\"Starting training for {epochs} epochs...\")\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "\n",
    "\n",
    "    print(\"Evaluating the model on the test set...\")\n",
    "    test_results = model.evaluate(test_dataset, verbose=1)\n",
    "    print(\"Evaluation on test set completed.\")\n",
    "\n",
    "\n",
    "    # Map Test Metrics\n",
    "\n",
    "\n",
    "    metric_names = model.metrics_names\n",
    "    test_metrics = dict(zip(metric_names, test_results))\n",
    "\n",
    "    test_metrics = {k: float(v) for k, v in test_metrics.items()}\n",
    "\n",
    "    # Initialize Training Info\n",
    "\n",
    "    training_info = {\n",
    "        \"Model\": model_name,\n",
    "        \"epochs\": epochs,\n",
    "        \"initial_learning_rate\": learning_rate,\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"patience\": patience,\n",
    "        \"train_metrics\": {},\n",
    "        \"val_metrics\": {},\n",
    "        \"test_metrics\": test_metrics\n",
    "    }\n",
    "\n",
    "\n",
    "    # Populate Training Metrics\n",
    "\n",
    "\n",
    "    for key, values in history.history.items():\n",
    "        if key.startswith('val_'):\n",
    "            # Validation metric\n",
    "            metric_name = key  \n",
    "            if metric_name not in training_info['val_metrics']:\n",
    "                training_info['val_metrics'][metric_name] = []\n",
    "            training_info['val_metrics'][metric_name].extend([float(v) for v in values])\n",
    "        else:\n",
    "            metric_name = key\n",
    "            if metric_name not in training_info['train_metrics']:\n",
    "                training_info['train_metrics'][metric_name] = []\n",
    "            training_info['train_metrics'][metric_name].extend([float(v) for v in values])\n",
    "\n",
    "\n",
    "    # Save the Model\n",
    "    model_path = os.path.join(model_dir, f'{model_name}.h5')\n",
    "    print(f\"Saving the model to {model_path}...\")\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved successfully.\")\n",
    "\n",
    "    # Save the Training Info\n",
    "    info_path = os.path.join(model_dir, f'{model_name}_training_info.json')\n",
    "    print(f\"Saving the training info to {info_path}...\")\n",
    "    with open(info_path, 'w') as f:\n",
    "        json.dump(training_info, f, indent=4)\n",
    "    print(\"Training info saved successfully.\")\n",
    "\n",
    "    print(f\"Model and training info saved in: {model_dir}\")\n",
    "    return history, training_info\n"
   ],
   "id": "468d66499e3b504a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T00:23:20.279541Z",
     "start_time": "2024-11-19T00:23:20.236120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_continue_training_multi_task_model(model_name,\n",
    "                                                results_dir='../results/Multi_Task',\n",
    "                                                additional_epochs=10,\n",
    "                                                learning_rate=None,\n",
    "                                                patience=5):\n",
    "\n",
    "    # Define Paths\n",
    "    model_dir = os.path.join(results_dir, model_name)\n",
    "    model_path = os.path.join(model_dir, f'{model_name}.h5')\n",
    "    info_path = os.path.join(model_dir, f'{model_name}_training_info.json')\n",
    "\n",
    "    # Load the Model\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "\n",
    "    # Load Existing Training Info\n",
    "    print(f\"Loading training info from {info_path}...\")\n",
    "    with open(info_path, 'r') as f:\n",
    "        training_info = json.load(f)\n",
    "    print(\"Training info loaded successfully.\")\n",
    "\n",
    "    current_lr = training_info.get(\"initial_learning_rate\", 1e-4)\n",
    "    new_lr = learning_rate if learning_rate is not None else current_lr\n",
    "    if learning_rate is not None:\n",
    "        print(f\"Updating learning rate from {current_lr} to {new_lr}\")\n",
    "\n",
    "\n",
    "    #  Recompile the Model with Updated Learning Rate\n",
    "    \n",
    "    print(\"Re-compiling the model with updated learning rate and weighted metrics...\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=new_lr)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss={\n",
    "            'face_output': 'binary_crossentropy',\n",
    "            'age_output': 'categorical_crossentropy',\n",
    "            'gender_output': 'binary_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'face_output': 'binary_accuracy',\n",
    "            'age_output': 'categorical_accuracy',\n",
    "            'gender_output': 'binary_accuracy'\n",
    "        },\n",
    "        weighted_metrics={\n",
    "            'age_output': 'categorical_accuracy',\n",
    "            'gender_output': 'binary_accuracy'\n",
    "        }\n",
    "    )\n",
    "    print(\"Model re-compiled successfully.\")\n",
    "\n",
    "\n",
    "    # Define Callbacks\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_age_output_categorical_accuracy',\n",
    "            factor=0.5,\n",
    "            patience=patience,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Continue Training\n",
    "    print(f\"Starting training for {additional_epochs} additional epochs...\")\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=additional_epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    print(\"Additional training completed.\")\n",
    "\n",
    "    # Evaluate on Test Data\n",
    "    print(\"Evaluating the updated model on the test set...\")\n",
    "    test_results = model.evaluate(test_dataset, verbose=1)\n",
    "    print(\"Evaluation on test set completed.\")\n",
    "\n",
    "    metric_names = model.metrics_names\n",
    "    test_metrics = dict(zip(metric_names, test_results))\n",
    "\n",
    "    # Convert test_metrics values to native Python types\n",
    "    test_metrics = {k: float(v) for k, v in test_metrics.items()}\n",
    "\n",
    "\n",
    "    # Append New Training History to Training Info\n",
    "    print(\"Appending new training metrics to training_info...\")\n",
    "    \n",
    "    training_info.setdefault('train_metrics', {})\n",
    "    training_info.setdefault('val_metrics', {})\n",
    "    training_info.setdefault('epochs', 0)\n",
    "\n",
    "    for key, values in history.history.items():\n",
    "        if key.startswith('val_'):\n",
    "            metric_name = key \n",
    "            if metric_name not in training_info['val_metrics']:\n",
    "                training_info['val_metrics'][metric_name] = []\n",
    "            training_info['val_metrics'][metric_name].extend([float(v) for v in values])\n",
    "        else:\n",
    "            metric_name = key\n",
    "            if metric_name not in training_info['train_metrics']:\n",
    "                training_info['train_metrics'][metric_name] = []\n",
    "            training_info['train_metrics'][metric_name].extend([float(v) for v in values])\n",
    "    print(\"Training metrics appended successfully.\")\n",
    "\n",
    "    #  Update Epoch Count\n",
    "    print(\"Updating epoch count in training_info...\")\n",
    "    training_info[\"epochs\"] += additional_epochs\n",
    "    print(f\"Total epochs after update: {training_info['epochs']}\")\n",
    "\n",
    "\n",
    "    # Replace Test Metrics\n",
    "    print(\"Replacing test metrics in training_info...\")\n",
    "    training_info[\"test_metrics\"] = test_metrics\n",
    "    print(\"Test metrics replaced successfully.\")\n",
    "\n",
    "\n",
    "    # Save the Updated Model\n",
    "    print(f\"Saving the updated model to {model_path}...\")\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved successfully.\")\n",
    "\n",
    "\n",
    "    # Save the Updated Training Info\n",
    "    print(f\"Saving the updated training info to {info_path}...\")\n",
    "    with open(info_path, 'w') as f:\n",
    "        json.dump(training_info, f, indent=4)\n",
    "    print(\"Training info saved successfully.\")\n",
    "\n",
    "    print(f\"Model and training info updated and saved in: {model_dir}\")\n",
    "    return history, training_info\n"
   ],
   "id": "44f9176d839d57fb",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
