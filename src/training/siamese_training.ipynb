{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-18T02:27:07.382644Z",
     "start_time": "2025-01-18T02:27:04.060003Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import os, sys\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T02:27:07.398309Z",
     "start_time": "2025-01-18T02:27:07.389982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..','data_processing')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..','models')))"
   ],
   "id": "38c705816f86895e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import contrastive data",
   "id": "16d3d7237e0d5b64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from contrastive_preprocessing import train_contrastive_dataset, val_contrastive_dataset",
   "id": "b4e57dab4f0c7fa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import triplet data",
   "id": "7ac447b91b888983"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from triplet_preprocessing import train_triplet_dataset, val_triplet_dataset",
   "id": "f726ad88b73da749",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import contrastive models",
   "id": "d4091254eafb8bf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T02:31:20.343319Z",
     "start_time": "2025-01-18T02:31:20.325477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from contrastive_v1 import create_and_compile_contrastive_v1\n",
    "from contrastive_v2 import create_and_compile_contrastive_v2\n",
    "from contrastive_v3 import create_and_compile_contrastive_v3"
   ],
   "id": "894f7720d80ccb03",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import triplet models",
   "id": "ddad95260e7ea89d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T02:27:12.499804Z",
     "start_time": "2025-01-18T02:27:12.479362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from triplet_v4 import create_and_compile_triplet_v4\n",
    "from triplet_v5 import create_and_compile_triplet_v5\n",
    "from triplet_v6 import create_and_compile_triplet_v6"
   ],
   "id": "8d2824488a11a57d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train or continue training the models",
   "id": "3ed26f2052b5584d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T02:28:49.848333Z",
     "start_time": "2025-01-18T02:28:49.832357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        epochs,\n",
    "        steps_per_epoch,\n",
    "        validation_steps,\n",
    "        initial_epoch=0,\n",
    "        base_dir='../results/siamese',\n",
    "        model_type='contrastive',  # 'contrastive' or 'triplet'\n",
    "        model_name=None,\n",
    "        batch_size=32,\n",
    "        patience=10,\n",
    "        previous_history_path=None\n",
    "):\n",
    "    # Set default model name if none provided\n",
    "    if model_name is None:\n",
    "        model_name = f\"{model_type}_basic\"\n",
    "\n",
    "    # Create directory structure\n",
    "    model_dir = os.path.join(base_dir, model_type, model_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Define paths\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    training_info_path = os.path.join(model_dir, f'{model_name}_training_info_{current_time}.json')\n",
    "    best_model_path = os.path.join(model_dir, f'{model_name}_best_{current_time}.h5')\n",
    "\n",
    "    # Initialize training info\n",
    "    training_info = {\n",
    "        \"model_name\": model_name,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs_completed\": 0,\n",
    "        \"training_history\": {}\n",
    "    }\n",
    "\n",
    "    # Load previous history if provided\n",
    "    if previous_history_path and os.path.exists(previous_history_path):\n",
    "        with open(previous_history_path, 'r') as f:\n",
    "            previous_info = json.load(f)\n",
    "            training_info[\"training_history\"] = previous_info[\"training_history\"]\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            best_model_path,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        initial_epoch=initial_epoch,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Update training history\n",
    "    for key in history.history:\n",
    "        if key not in training_info[\"training_history\"]:\n",
    "            training_info[\"training_history\"][key] = []\n",
    "        training_info[\"training_history\"][key].extend(\n",
    "            [float(val) for val in history.history[key]]\n",
    "        )\n",
    "\n",
    "    training_info[\"epochs_completed\"] = epochs\n",
    "\n",
    "    # Save updated training info\n",
    "    with open(training_info_path, 'w') as f:\n",
    "        json.dump(training_info, f, indent=4)\n",
    "\n",
    "    return history"
   ],
   "id": "f51e2cde3d395e8a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example usage",
   "id": "464ccd3328d6cc38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "v1 = create_and_compile_contrastive_v1(dropout_rate=0.3, learning_rate=0.001)",
   "id": "b96be9d641646dd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "history = train_model(v1,train_contrastive_dataset,val_contrastive_dataset,100,4000,2000,model_name='contrastive_v1',model_type='contrastive')",
   "id": "10d477763883c4c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
