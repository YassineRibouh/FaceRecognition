{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T12:12:41.180083Z",
     "start_time": "2024-12-09T12:12:12.182537Z"
    }
   },
   "source": [
    "import os, sys, json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T12:12:41.210064Z",
     "start_time": "2024-12-09T12:12:41.203467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..','data_processing')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..','models')))"
   ],
   "id": "f69171045d99a6c1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T12:12:41.241945Z",
     "start_time": "2024-12-09T12:12:41.223455Z"
    }
   },
   "cell_type": "code",
   "source": "tf.random.set_seed(42)",
   "id": "4c21dd7ff5669eaf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T12:12:49.836061Z",
     "start_time": "2024-12-09T12:12:41.428848Z"
    }
   },
   "cell_type": "code",
   "source": "from gan_preprocessing import dataset ",
   "id": "f1ff7870ae02e652",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:31:11.823272Z",
     "start_time": "2024-12-08T21:31:11.809766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gan2 import create_gan2\n",
    "from gan3 import create_gan3"
   ],
   "id": "1439ce9ac39d12c9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "D accuracy real: 0.6-0.9\n",
    "D accuracy fake: 0.6-0.9\n",
    "D loss: 0.3-0.7\n",
    "G loss: 0.7-2.0"
   ],
   "id": "3bd25d083943f522"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:29:06.533145Z",
     "start_time": "2024-12-08T21:29:06.507533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_gan(\n",
    "        generator,\n",
    "        discriminator,\n",
    "        gan,\n",
    "        dataset,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        latent_dim=120,\n",
    "        save_dir='gan_training',\n",
    "        starting_epoch=0,\n",
    "        checkpoint_interval=10,  # Save models every 5 epochs\n",
    "        sample_interval=5      # Generate images every 10 epochs\n",
    "):\n",
    "    save_dir = Path(save_dir)\n",
    "    models_dir = save_dir / 'models'\n",
    "    samples_dir = save_dir / 'samples'\n",
    "\n",
    "    for dir_path in [save_dir, models_dir, samples_dir]:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    history = {\n",
    "        'training_config': {\n",
    "            'batch_size': int(batch_size),\n",
    "            'latent_dim': int(latent_dim),\n",
    "            'starting_epoch': int(starting_epoch),\n",
    "            'total_epochs': int(epochs),\n",
    "            'checkpoint_interval': int(checkpoint_interval),\n",
    "            'sample_interval': int(sample_interval),\n",
    "            'start_time': datetime.now().isoformat()\n",
    "        },\n",
    "        'epochs': []\n",
    "    }\n",
    "\n",
    "    def save_images(epoch):\n",
    "        noise = tf.random.normal([25, latent_dim])\n",
    "        generated = generator(noise, training=False)\n",
    "        generated = (generated + 1) / 2.0\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(25):\n",
    "            plt.subplot(5, 5, i + 1)\n",
    "            plt.imshow(generated[i])\n",
    "            plt.axis('off')\n",
    "        plt.savefig(samples_dir / f'epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def save_checkpoint(epoch, d_losses, g_losses):\n",
    "        epoch_stats = {\n",
    "            'epoch_number': int(epoch),\n",
    "            'epoch_completed': datetime.now().isoformat(),\n",
    "            'mean_d_loss': float(np.mean(d_losses)),\n",
    "            'mean_g_loss': float(np.mean(g_losses)),\n",
    "            'std_d_loss': float(np.std(d_losses)),\n",
    "            'std_g_loss': float(np.std(g_losses))\n",
    "        }\n",
    "        history['epochs'].append(epoch_stats)\n",
    "\n",
    "        # Save current state\n",
    "        checkpoint_dir = models_dir / f'checkpoint_epoch_{epoch}'\n",
    "        checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Save full models\n",
    "        generator.save(checkpoint_dir / 'generator.h5',include_optimizer=True)\n",
    "        discriminator.save(checkpoint_dir / 'discriminator.h5', include_optimizer=True)\n",
    "\n",
    "        # Save training history\n",
    "        with open(save_dir / 'training_history.json', 'w') as f:\n",
    "            json.dump(history, f, indent=4)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(starting_epoch, starting_epoch + epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}\")\n",
    "        epoch_d_losses = []\n",
    "        epoch_g_losses = []\n",
    "        batch_count = 0\n",
    "\n",
    "        for batch in dataset:\n",
    "            batch_size = tf.shape(batch)[0]\n",
    "\n",
    "            # Train discriminator\n",
    "            noise = tf.random.normal([batch_size, latent_dim])\n",
    "            generated_images = generator(noise, training=True)\n",
    "\n",
    "            real_labels = tf.random.uniform([batch_size, 1], 0.8, 1.0)\n",
    "            fake_labels = tf.random.uniform([batch_size, 1], 0.0, 0.2)\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(batch, real_labels)\n",
    "            loss_real = d_loss_real[0] \n",
    "\n",
    "            # Train discriminator on fake images\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "            loss_fake = d_loss_fake[0]\n",
    "\n",
    "            # Compute the average loss\n",
    "            d_loss = 0.5 * (loss_real + loss_fake)\n",
    "\n",
    "\n",
    "            # Train generator\n",
    "            noise = tf.random.normal([batch_size * 2, latent_dim])\n",
    "            g_loss = gan.train_on_batch(noise, tf.ones([batch_size * 2, 1]))\n",
    "\n",
    "            epoch_d_losses.append(float(d_loss))\n",
    "            epoch_g_losses.append(float(g_loss))\n",
    "\n",
    "            if batch_count % 50 == 0:\n",
    "                print(f\"Batch {batch_count}: d_loss={d_loss:.4f}, g_loss={g_loss:.4f}\")\n",
    "            batch_count += 1\n",
    "\n",
    "        # Save samples every sample_interval epochs\n",
    "        if (epoch + 1) % sample_interval == 0:\n",
    "            print(f\"Generating sample images at epoch {epoch + 1}\")\n",
    "            save_images(epoch + 1)\n",
    "\n",
    "        # Save checkpoint every checkpoint_interval epochs\n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            print(f\"Saving checkpoint at epoch {epoch + 1}\")\n",
    "            save_checkpoint(epoch + 1, epoch_d_losses, epoch_g_losses)\n",
    "\n",
    "        # Always update history\n",
    "        with open(save_dir / 'training_history.json', 'w') as f:\n",
    "            json.dump(history, f, indent=4)\n",
    "\n",
    "    # Save final checkpoint regardless of interval\n",
    "    save_checkpoint(starting_epoch + epochs, epoch_d_losses, epoch_g_losses)\n",
    "    print(f\"\\nTraining completed in {time.time() - start_time:.1f} seconds\")\n",
    "    return history"
   ],
   "id": "5b8642d1376a875b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T12:17:55.013826Z",
     "start_time": "2024-12-09T12:17:55.000332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_gan_checkpoint(checkpoint_dir, latent_dim=120):\n",
    "\n",
    "    checkpoint_dir = Path(checkpoint_dir)\n",
    "\n",
    "# Load full models\n",
    "    generator = tf.keras.models.load_model(checkpoint_dir / 'generator.h5', compile=False)\n",
    "    discriminator = tf.keras.models.load_model(checkpoint_dir / 'discriminator.h5', compile=False)\n",
    "\n",
    "# Recreate GAN\n",
    "    discriminator.trainable = False\n",
    "    gan_input = tf.keras.Input(shape=(latent_dim,))\n",
    "    gan_output = discriminator(generator(gan_input))\n",
    "    gan = tf.keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "# Compile with same settings\n",
    "    discriminator.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(2e-8, beta_1=0.5, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    gan.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(2e-8, beta_1=0.5, clipvalue=1.0),\n",
    "    loss='binary_crossentropy'\n",
    "    )\n",
    "\n",
    "    return generator, discriminator, gan"
   ],
   "id": "dcb8ad038e1e2274",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:02:52.139170Z",
     "start_time": "2024-12-09T16:02:52.054089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_and_save_images(generator_path, save_dir, num_images=50, latent_dim=100):\n",
    "    # Load the trained generator model\n",
    "    generator = load_model(generator_path)\n",
    "    print(f\"Loaded generator model from {generator_path}\")\n",
    "\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Images will be saved to {save_dir.resolve()}\")\n",
    "\n",
    "    batch_size = 32\n",
    "    num_full_batches = num_images // batch_size\n",
    "    remaining_images = num_images % batch_size\n",
    "\n",
    "    image_count = 0 \n",
    "\n",
    "    def save_image(tensor, sample_number):\n",
    "        # Scale from [-1, 1] to [0, 255]\n",
    "        img = (tensor * 127.5 + 127.5).numpy().astype('uint8')\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        # Get the current date \n",
    "        current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")[:-3]  # Up to milliseconds\n",
    "\n",
    "        # Create a unique filename\n",
    "        img_filename = save_dir / f\"image_{sample_number:05d}_{current_datetime}.png\"\n",
    "\n",
    "        # Save the image\n",
    "        img.save(img_filename)\n",
    "\n",
    "    # Generate and save full batches\n",
    "    for batch in range(num_full_batches):\n",
    "        noise = tf.random.normal([batch_size, latent_dim])\n",
    "        generated_images = generator(noise, training=False)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            img_tensor = generated_images[i]\n",
    "            image_count += 1\n",
    "            save_image(img_tensor, image_count)\n",
    "\n",
    "            if image_count % 100 == 0:\n",
    "                print(f\"{image_count} images generated and saved.\")\n",
    "\n",
    "    if remaining_images > 0:\n",
    "        noise = tf.random.normal([remaining_images, latent_dim])\n",
    "        generated_images = generator(noise, training=False)\n",
    "\n",
    "        for i in range(remaining_images):\n",
    "            img_tensor = generated_images[i]\n",
    "            image_count += 1\n",
    "            save_image(img_tensor, image_count)\n",
    "\n",
    "            if image_count % 100 == 0:\n",
    "                print(f\"{image_count} images generated and saved.\")\n",
    "\n",
    "    print(f\"Image generation complete. {image_count} images saved to {save_dir.resolve()}\")\n"
   ],
   "id": "ff10847fa6fecb72",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
