{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-19T18:14:50.586836Z",
     "start_time": "2025-01-19T18:14:45.397996Z"
    }
   },
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:14:50.601611Z",
     "start_time": "2025-01-19T18:14:50.593121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..','data_processing')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..','models')))"
   ],
   "id": "83f411dcfb893465",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from triplet_preprocessing import test_triplet_dataset",
   "id": "8f0e803954e2bf47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluates the triplet models on the test dataset by computing similarity scores generating ROC and PR curves and calculating performance metrics at a given threshold",
   "id": "f2c5afdba9018f60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:39:26.535126Z",
     "start_time": "2025-01-19T18:39:26.501276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_on_test(\n",
    "        model,\n",
    "        test_dataset,\n",
    "        optimal_threshold=0.75,\n",
    "        num_test_steps=2000\n",
    "):\n",
    "\n",
    "    embedding_network = model.get_layer('EmbeddingNetwork')\n",
    "    positive_similarities = []\n",
    "    negative_similarities = []\n",
    "\n",
    "    print(\"Computing similarities from test dataset\")\n",
    "    for anchors, positives, negatives in tqdm(test_dataset.take(num_test_steps)):\n",
    "        # Compute embeddings\n",
    "        anchor_embeddings = embedding_network.predict(anchors, verbose=0)\n",
    "        positive_embeddings = embedding_network.predict(positives, verbose=0)\n",
    "        negative_embeddings = embedding_network.predict(negatives, verbose=0)\n",
    "\n",
    "        # Compute similarities and normalize to [0,1] range\n",
    "        for i in range(len(anchor_embeddings)):\n",
    "            # Compute cosine similarity\n",
    "            pos_sim = np.dot(anchor_embeddings[i], positive_embeddings[i]) / (\n",
    "                    np.linalg.norm(anchor_embeddings[i]) * np.linalg.norm(positive_embeddings[i])\n",
    "            )\n",
    "            # Convert from [-1,1] to [0,1]\n",
    "            pos_sim = (pos_sim + 1) / 2\n",
    "            positive_similarities.append(pos_sim)\n",
    "\n",
    "            neg_sim = np.dot(anchor_embeddings[i], negative_embeddings[i]) / (\n",
    "                    np.linalg.norm(anchor_embeddings[i]) * np.linalg.norm(negative_embeddings[i])\n",
    "            )\n",
    "            # Convert from [-1,1] to [0,1]\n",
    "            neg_sim = (neg_sim + 1) / 2\n",
    "            negative_similarities.append(neg_sim)\n",
    "\n",
    "    # Prepare test data\n",
    "    y_true = np.concatenate([np.ones(len(positive_similarities)),\n",
    "                             np.zeros(len(negative_similarities))])\n",
    "    y_scores = np.concatenate([positive_similarities, negative_similarities])\n",
    "\n",
    "    # Compute ROC and PR curves\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    # Calculate metrics using optimal threshold\n",
    "    predictions = (y_scores >= optimal_threshold).astype(int)\n",
    "    tp = np.sum((predictions == 1) & (y_true == 1))\n",
    "    fp = np.sum((predictions == 1) & (y_true == 0))\n",
    "    tn = np.sum((predictions == 0) & (y_true == 0))\n",
    "    fn = np.sum((predictions == 0) & (y_true == 1))\n",
    "\n",
    "    test_metrics = {\n",
    "        'accuracy': (tp + tn) / len(y_true),\n",
    "        'precision': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'recall': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'f1': 2 * (tp / (tp + fp)) * (tp / (tp + fn)) / ((tp / (tp + fp)) + (tp / (tp + fn))) if (tp + fp) > 0 and (tp + fn) > 0 else 0,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc\n",
    "    }\n",
    "\n",
    "    # Plot ROC and PR curves\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # ROC curve\n",
    "    plt.subplot(131)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Test ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Precision-Recall curve\n",
    "    plt.subplot(132)\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Test Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Similarity distributions (0-1 range)\n",
    "    plt.subplot(133)\n",
    "    plt.hist(positive_similarities, bins=50, alpha=0.5, label='Positive Pairs', density=True)\n",
    "    plt.hist(negative_similarities, bins=50, alpha=0.5, label='Negative Pairs', density=True)\n",
    "    plt.axvline(x=optimal_threshold, color='r', linestyle='--', label='Optimal Threshold')\n",
    "    plt.xlabel('Similarity Score (0-1)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Test Similarity Distributions')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nTest Results:\")\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "\n",
    "    return test_metrics"
   ],
   "id": "15737ed626037762",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exmaple of evaluating a model",
   "id": "9b4925ae588217f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "v6 = load_model('../results/siamese/triplet/triplet_v6/triplet_v6.h5',compile=False)\n",
    "v6.compile()"
   ],
   "id": "d37a858e9f2367eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_results = evaluate_on_test(v6,test_triplet_dataset)",
   "id": "adff6064daee568f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
