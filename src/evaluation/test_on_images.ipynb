{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:29:10.822583Z",
     "start_time": "2025-01-12T12:29:03.799170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications import efficientnet_v2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "8729f250529adfb7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Processes an input image for a given model type in our case contrastive or triplet  by resizing and applying preprocessing\n",
   "id": "5feba2e8fe06ad82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_image(img_source, target_size=(128, 128), preTrained=False):\n",
    "    img = Image.open(img_source) if isinstance(img_source, str) else img_source\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    img_array = np.array(img)\n",
    "    if not isinstance(img_array, tf.Tensor):\n",
    "        img_array = tf.convert_to_tensor(img_array)\n",
    "    img_array = tf.image.resize(img_array, target_size)\n",
    "\n",
    "    if preTrained:\n",
    "        return efficientnet_v2.preprocess_input(img_array)\n",
    "    else:\n",
    "        return (img_array / 127.5) - 1.0"
   ],
   "id": "83d0f1f1708d75b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculates the similarity between two images\n",
   "id": "f4c6b8d3400be607"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_similarity(model, img1, img2, preTrained, model_type='contrastive', embedding_network_name='EmbeddingNetwork'):\n",
    "    img1_processed = process_image(img1, preTrained=preTrained)\n",
    "    img2_processed = process_image(img2, preTrained=preTrained)\n",
    "\n",
    "    if model_type == 'contrastive':\n",
    "        distance = model.predict(\n",
    "            [np.expand_dims(img1_processed, 0), np.expand_dims(img2_processed, 0)],\n",
    "            verbose=0\n",
    "        )[0][0]\n",
    "        similarity = 1.0 / (1.0 + distance)\n",
    "        return similarity\n",
    "    else:\n",
    "        embedding_network = model.get_layer(embedding_network_name)\n",
    "        emb1 = embedding_network.predict(np.expand_dims(img1_processed, 0), verbose=0)\n",
    "        emb2 = embedding_network.predict(np.expand_dims(img2_processed, 0), verbose=0)\n",
    "        similarity = np.dot(emb1[0], emb2[0])\n",
    "        return (similarity + 1) / 2"
   ],
   "id": "9a49bbbc6d301d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Verifies if two face images match by computing their similarity and comparing it to a threshold",
   "id": "56d3e44bcbb6061f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def verify_faces(model, img1_path, img2_path, preTrained, model_type='contrastive',\n",
    "                 threshold=0.75, embedding_network_name='EmbeddingNetwork'):\n",
    "\n",
    "    similarity = get_similarity(\n",
    "        model, img1_path, img2_path,\n",
    "        preTrained,\n",
    "        model_type=model_type,\n",
    "        embedding_network_name=embedding_network_name\n",
    "    )\n",
    "\n",
    "    is_match = similarity >= threshold\n",
    "\n",
    "    return {\n",
    "        'is_match': is_match,\n",
    "        'similarity': float(similarity),\n",
    "        'image1': img1_path,\n",
    "        'image2': img2_path\n",
    "    }"
   ],
   "id": "99eae250e4e98044"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Identifies matching faces by comparing a probe image against a gallery of images returning top matches above a similarity threshold\n",
   "id": "859b75fbadd6a3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def identify_faces(model, probe_image, gallery_folder, preTrained, model_type='contrastive',\n",
    "                   threshold=0.2, top_k=5, embedding_network_name='EmbeddingNetwork'):\n",
    "    # Get all images\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.webp'}\n",
    "    gallery_images = [\n",
    "        str(f) for f in Path(gallery_folder).iterdir()\n",
    "        if f.suffix.lower() in valid_extensions\n",
    "    ]\n",
    "\n",
    "    if not gallery_images:\n",
    "        return {\n",
    "            'probe_image': probe_image,\n",
    "            'matches': [],\n",
    "            'match_found': False\n",
    "        }\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for gallery_img in gallery_images:\n",
    "        similarity = get_similarity(\n",
    "            model, probe_image, gallery_img,\n",
    "            preTrained,\n",
    "            model_type=model_type,\n",
    "            embedding_network_name=embedding_network_name\n",
    "        )\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    similarities = np.array(similarities)\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    top_similarities = similarities[top_indices]\n",
    "\n",
    "    matches = []\n",
    "    for idx, sim in zip(top_indices, top_similarities):\n",
    "        if sim >= threshold:\n",
    "            matches.append({\n",
    "                'gallery_image': gallery_images[idx],\n",
    "                'similarity': float(sim)\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        'probe_image': probe_image,\n",
    "        'matches': matches,\n",
    "        'match_found': len(matches) > 0\n",
    "    }"
   ],
   "id": "db67ea91a4caba2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loads an image from disk and converts it into a numpy array for display",
   "id": "3a6ecd8118978565"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:50:06.065938Z",
     "start_time": "2025-01-12T12:50:06.045851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_display_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    return np.array(img)"
   ],
   "id": "e88323ea5cf28cb3",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Displays face verification results",
   "id": "ba4308584adc2437"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_verification_results(verification_results, save_path=None):\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "    gs = plt.GridSpec(2, 2, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "    img1 = load_display_image(verification_results['image1'])\n",
    "    img2 = load_display_image(verification_results['image2'])\n",
    "\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title('Image 1', pad=10)\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title('Image 2', pad=10)\n",
    "    ax2.axis('off')\n",
    "\n",
    "    similarity = verification_results['similarity']\n",
    "    ax3.barh(y=0, width=100, height=0.3, color='lightgray')\n",
    "    bar_color = 'green' if verification_results['is_match'] else 'red'\n",
    "    display_width = min(100, max(0, similarity * 100))\n",
    "    ax3.barh(y=0, width=display_width, height=0.3, color=bar_color)\n",
    "\n",
    "    ax3.text(50, 0.5, f\"Similarity: {similarity:.3f}\",\n",
    "             ha='center', va='bottom', fontsize=12)\n",
    "    match_text = \"MATCH\" if verification_results['is_match'] else \"NO MATCH\"\n",
    "    match_color = \"green\" if verification_results['is_match'] else \"red\"\n",
    "    ax3.text(50, -0.5, match_text, ha='center', va='top',\n",
    "             fontsize=14, fontweight='bold', color=match_color)\n",
    "\n",
    "    ax3.set_xlim(-5, 105)\n",
    "    ax3.set_ylim(-1, 1)\n",
    "    ax3.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Face Verification Results\", fontsize=14, y=0.95)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "6c317b6204aa1783"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualizes face identification results",
   "id": "ed05b87247f278b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:29:11.085306Z",
     "start_time": "2025-01-12T12:29:11.056880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_identification_results(identification_results, save_path=None):\n",
    "    plt.style.use('default')\n",
    "    n_matches = len(identification_results['matches'])\n",
    "    if n_matches == 0:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.text(0.5, 0.5, \"NO MATCHES FOUND\",\n",
    "                 ha='center', va='center', fontsize=20, color='red')\n",
    "        plt.axis('off')\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    n_cols = min(3, n_matches + 1)\n",
    "    n_rows = (n_matches + 2) // n_cols\n",
    "    fig = plt.figure(figsize=(4*n_cols, 4*n_rows))\n",
    "\n",
    "    ax_probe = plt.subplot(n_rows, n_cols, 1)\n",
    "    probe_img = load_display_image(identification_results['probe_image'])\n",
    "    ax_probe.imshow(probe_img)\n",
    "    ax_probe.set_title('Probe Image', fontsize=12, pad=10)\n",
    "    ax_probe.axis('off')\n",
    "\n",
    "    for idx, match in enumerate(identification_results['matches'], 2):\n",
    "        ax = plt.subplot(n_rows, n_cols, idx)\n",
    "        gallery_img = load_display_image(match['gallery_image'])\n",
    "        ax.imshow(gallery_img)\n",
    "        score_color = 'green' if match['similarity'] > 0.7 else 'orange'\n",
    "        ax.set_title(f\"Match {idx-1}\\nSimilarity: {match['similarity']:.3f}\",\n",
    "                     fontsize=12, pad=10, color=score_color)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Face Identification Results\", fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "1f5c168ea990f739",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load the model\n",
    "v1 = load_model('../results/siamese/contrastive_v1/contrastive_v1.h5', compile=False)\n",
    "v1.compile()"
   ],
   "id": "d03fa8ac04bf8af8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Verification example",
   "id": "de5f2ebdce70eb05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "verification_results = verify_faces(\n",
    "    model=v1,\n",
    "    img1_path='path/to/person1_photo1.jpg',\n",
    "    img2_path='path/to/person1_photo2.jpg',\n",
    "    preTrained=False,  # Set to True if using EfficientNet model\n",
    "    model_type='contrastive',  # or triplet\n",
    "    threshold=0.75  # Adjust threshold \n",
    ")\n"
   ],
   "id": "b7de9ec17a044020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize the verification results\n",
    "visualize_verification_results(verification_results)"
   ],
   "id": "1f02e36c95aa7c19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### identification example",
   "id": "eb86e8a695b30d47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Search for matching faces in a gallery\n",
    "identification_results = identify_faces(\n",
    "    model=v1,\n",
    "    probe_image='path/to/probe_image.jpg',\n",
    "    gallery_folder='path/to/gallery_folder',\n",
    "    preTrained=False, # Set to True if using EfficientNet model\n",
    "    model_type='contrastive',\n",
    "    threshold=0.75, # or triplet\n",
    "    top_k=5  # Return top k (5 or ...) matches\n",
    ")"
   ],
   "id": "3451bd8fa03e5f31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize the identification results\n",
    "visualize_identification_results(identification_results)"
   ],
   "id": "4f78e1190ac52dee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
