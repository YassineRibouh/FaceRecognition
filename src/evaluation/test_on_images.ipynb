{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:21.991480Z",
     "start_time": "2024-11-19T09:11:01.565360Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import io"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:22.023175Z",
     "start_time": "2024-11-19T09:11:22.010047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Existing preprocessing configurations and mappings\n",
    "age_group_map = {\n",
    "    '18-29': 0,\n",
    "    '30-39': 1,\n",
    "    '40-49': 2,\n",
    "    '50-59': 3,\n",
    "    'more than 60': 4\n",
    "}\n",
    "\n",
    "# Reverse age group map for decoding predictions\n",
    "reverse_age_group_map = {v: k for k, v in age_group_map.items()}\n",
    "\n",
    "MODEL_MAP = {\n",
    "    1: {\n",
    "        'name': 'efficientnet_v2',\n",
    "        'preprocess': tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "        'input_size': (224, 224)\n",
    "    },\n",
    "    2: {\n",
    "        'name': 'resnet50',\n",
    "        'preprocess': tf.keras.applications.resnet50.preprocess_input,\n",
    "        'input_size': (224, 224)\n",
    "    },\n",
    "    3: {\n",
    "        'name': 'inception_v3',\n",
    "        'preprocess': tf.keras.applications.inception_v3.preprocess_input,\n",
    "        'input_size': (299, 299)\n",
    "    },\n",
    "    4: {\n",
    "        'name': 'mobilenet_v2',\n",
    "        'preprocess': tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        'input_size': (224, 224)\n",
    "    }\n",
    "}\n"
   ],
   "id": "acc1eeecfbfc548f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:22.070734Z",
     "start_time": "2024-11-19T09:11:22.037121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def select_model(model_path,selected_model_number):\n",
    "\n",
    "    model_info = MODEL_MAP[selected_model_number]\n",
    "    model_name = model_info['name']\n",
    "    preprocess_func = model_info['preprocess']\n",
    "    target_size = model_info['input_size']\n",
    "\n",
    "    print(f\"Loading model '{model_name}' from {model_path}...\")\n",
    "    model = load_model(model_path)\n",
    "    print(f\"Model '{model_name}' loaded successfully.\")\n",
    "\n",
    "    return model, preprocess_func, target_size\n",
    "\n",
    "def load_image(image_source, target_size):\n",
    "\n",
    "    try:\n",
    "        if image_source.startswith('http://') or image_source.startswith('https://'):\n",
    "            print(f\"Loading image from URL: {image_source}\")\n",
    "            response = urlopen(image_source)\n",
    "            image_data = response.read()\n",
    "            image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "        else:\n",
    "            print(f\"Loading image from path: {image_source}\")\n",
    "            image = Image.open(image_source).convert('RGB')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading image from {image_source}: {e}\")\n",
    "\n",
    "    image = image.resize(target_size)\n",
    "    image_array = np.array(image)\n",
    "    return image_array\n",
    "\n",
    "def predict_image(model, preprocess_func, target_size, image_source):\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = load_image(image_source, target_size)\n",
    "    image = preprocess_func(image)\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Run prediction\n",
    "    predictions = model.predict(image)\n",
    "\n",
    "    # Handle different model output structures\n",
    "    if isinstance(predictions, list):\n",
    "        if len(predictions) < 3:\n",
    "            raise ValueError(\"Model should have three outputs: face_output, age_output, gender_output.\")\n",
    "        face_pred, age_pred, gender_pred = predictions[:3]\n",
    "    elif isinstance(predictions, dict):\n",
    "        face_pred = predictions.get('face_output')\n",
    "        age_pred = predictions.get('age_output')\n",
    "        gender_pred = predictions.get('gender_output')\n",
    "        if face_pred is None or age_pred is None or gender_pred is None:\n",
    "            raise ValueError(\"Model outputs should include 'face_output', 'age_output', and 'gender_output'.\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model output format. Expected list or dict.\")\n",
    "\n",
    "    # Process face prediction\n",
    "    face_prob = float(face_pred[0][0]) \n",
    "    face_label = 1 if face_prob >= 0.5 else 0  \n",
    "\n",
    "    result = {'face': 'Face' if face_label == 1 else 'Non-Face'}\n",
    "\n",
    "    if face_label == 1:\n",
    "        # Process gender prediction\n",
    "        gender_prob = float(gender_pred[0][0])  \n",
    "        gender_label = 1 if gender_prob >= 0.5 else 0  # 1: Male, 0: Female\n",
    "        gender = 'Male' if gender_label == 1 else 'Female'\n",
    "        result['gender'] = gender\n",
    "\n",
    "        # Process age prediction\n",
    "        age_probs = age_pred[0]  \n",
    "        age_label = int(np.argmax(age_probs))\n",
    "        age_group = reverse_age_group_map.get(age_label, 'Unknown')\n",
    "        result['age'] = age_group\n",
    "\n",
    "    return result\n"
   ],
   "id": "346b682f836688a4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:32.778121Z",
     "start_time": "2024-11-19T09:11:22.309017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_model_number = 4\n",
    "model_path = '../results/Multi_Task/MobileNetV2_MultiTask/MobileNetV2_MultiTask.h5'\n",
    "model, preprocess_func, target_size = select_model(model_path,selected_model_number)\n",
    "\n",
    "# Predict on a new image\n",
    "image_source = 'https://cdn.prod.www.spiegel.de/images/49f97d1c-5277-477c-8040-bf78adaaa83f_w1024_r1.778_fpx48_fpy33.jpg'\n",
    "prediction = predict_image(model, preprocess_func, target_size, image_source)\n",
    "print(prediction)"
   ],
   "id": "17f4d7872d291f9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'mobilenet_v2' from ../results/Multi_Task/MobileNetV2_MultiTask/MobileNetV2_MultiTask.h5...\n",
      "Model 'mobilenet_v2' loaded successfully.\n",
      "Loading image from URL: https://cdn.prod.www.spiegel.de/images/49f97d1c-5277-477c-8040-bf78adaaa83f_w1024_r1.778_fpx48_fpy33.jpg\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "{'face': 'Face', 'gender': 'Male', 'age': 'more than 60'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:32.841454Z",
     "start_time": "2024-11-19T09:11:32.824376Z"
    }
   },
   "cell_type": "code",
   "source": "image_source='https://media.wired.com/photos/6643f935a984e349e5fda5a6/1:1/w_1600,h_1600,c_limit/Ilya-Sutskever-Leaves-OpenAI-Business-1258459705.jpg'",
   "id": "529bc13e5865bac1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:33.320005Z",
     "start_time": "2024-11-19T09:11:32.876297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = predict_image(model, preprocess_func, target_size, image_source)\n",
    "print(prediction)"
   ],
   "id": "47ee29676814f45c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from URL: https://media.wired.com/photos/6643f935a984e349e5fda5a6/1:1/w_1600,h_1600,c_limit/Ilya-Sutskever-Leaves-OpenAI-Business-1258459705.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "{'face': 'Face', 'gender': 'Male', 'age': '50-59'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:33.366880Z",
     "start_time": "2024-11-19T09:11:33.345937Z"
    }
   },
   "cell_type": "code",
   "source": "image_source='https://i.guim.co.uk/img/media/8649348d194259744b0d75240c711cb5d221de70/13_72_2386_1431/master/2386.jpg?width=1200&height=1200&quality=85&auto=format&fit=crop&s=d730f53ab1cc888740837e21c57ea047'",
   "id": "f9acd15fc311e2de",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:33.736239Z",
     "start_time": "2024-11-19T09:11:33.401626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = predict_image(model, preprocess_func, target_size, image_source)\n",
    "print(prediction)"
   ],
   "id": "fede828a5242a0f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from URL: https://i.guim.co.uk/img/media/8649348d194259744b0d75240c711cb5d221de70/13_72_2386_1431/master/2386.jpg?width=1200&height=1200&quality=85&auto=format&fit=crop&s=d730f53ab1cc888740837e21c57ea047\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "{'face': 'Face', 'gender': 'Female', 'age': '30-39'}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:33.768205Z",
     "start_time": "2024-11-19T09:11:33.755232Z"
    }
   },
   "cell_type": "code",
   "source": "image_source = 'https://www.rheinland-pilgern.de/data/ort/8/koelner-dom.8-1-5yduj.wide.jpg'",
   "id": "cf85716552b59667",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T09:11:34.174791Z",
     "start_time": "2024-11-19T09:11:33.786661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = predict_image(model, preprocess_func, target_size, image_source)\n",
    "print(prediction)"
   ],
   "id": "9b344df4c2aa5296",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from URL: https://www.rheinland-pilgern.de/data/ort/8/koelner-dom.8-1-5yduj.wide.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "{'face': 'Non-Face'}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba5140048321da7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
